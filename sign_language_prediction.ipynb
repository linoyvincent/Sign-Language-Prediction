{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9HpAqBAsKOT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from PIL import Image\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlBCiq8MsMnt"
      },
      "outputs": [],
      "source": [
        "# Define model architecture\n",
        "def create_asl_image_model(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FlNasBbsPS0"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel 'Python 3.10.11' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Path to train directory\n",
        "train_dir = 'asl_alphabet_train\\asl_alphabet_train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWFOrqfxsSEv",
        "outputId": "55e49af6-a991-40bd-bfe3-57ac0fa3d533"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 87000 images belonging to 29 classes.\n"
          ]
        }
      ],
      "source": [
        "# Data generators for training data\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, zoom_range=0.2, horizontal_flip=True)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, target_size=(64, 64), batch_size=32, class_mode='sparse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhgPsUWasU0Z"
      },
      "outputs": [],
      "source": [
        "# Create and train the model\n",
        "input_shape = (64, 64, 3)\n",
        "num_classes = len(os.listdir(train_dir))  # Number of folders in the train directory corresponds to the number of classes\n",
        "asl_image_model = create_asl_image_model(input_shape, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IyyBzVV0rIF"
      },
      "outputs": [],
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    'sign_language.model.h5',\n",
        "    monitor='accuracy',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode='auto',\n",
        "    save_freq='epoch'\n",
        ")\n",
        "\n",
        "Early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='accuracy',\n",
        "    patience=8,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3TG45ArsYnj",
        "outputId": "acb6f9e8-7efd-4305-fded-e0ae1344d5bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2719/2719 [==============================] - ETA: 0s - loss: 0.3233 - accuracy: 0.8904\n",
            "Epoch 1: accuracy improved from -inf to 0.89039, saving model to /content/drive/MyDrive/predicting_sign_language/sign_language.model.h5\n",
            "2719/2719 [==============================] - 181s 66ms/step - loss: 0.3233 - accuracy: 0.8904\n",
            "Epoch 2/10\n",
            "   1/2719 [..............................] - ETA: 4:10 - loss: 0.3449 - accuracy: 0.8750"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2719/2719 [==============================] - ETA: 0s - loss: 0.1951 - accuracy: 0.9343\n",
            "Epoch 2: accuracy improved from 0.89039 to 0.93431, saving model to /content/drive/MyDrive/predicting_sign_language/sign_language.model.h5\n",
            "2719/2719 [==============================] - 179s 66ms/step - loss: 0.1951 - accuracy: 0.9343\n",
            "Epoch 3/10\n",
            "2719/2719 [==============================] - ETA: 0s - loss: 0.1422 - accuracy: 0.9518\n",
            "Epoch 3: accuracy improved from 0.93431 to 0.95178, saving model to /content/drive/MyDrive/predicting_sign_language/sign_language.model.h5\n",
            "2719/2719 [==============================] - 183s 67ms/step - loss: 0.1422 - accuracy: 0.9518\n",
            "Epoch 4/10\n",
            "2719/2719 [==============================] - ETA: 0s - loss: 0.1153 - accuracy: 0.9612\n",
            "Epoch 4: accuracy improved from 0.95178 to 0.96124, saving model to /content/drive/MyDrive/predicting_sign_language/sign_language.model.h5\n",
            "2719/2719 [==============================] - 179s 66ms/step - loss: 0.1153 - accuracy: 0.9612\n",
            "Epoch 5/10\n",
            "2719/2719 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.9675\n",
            "Epoch 5: accuracy improved from 0.96124 to 0.96753, saving model to /content/drive/MyDrive/predicting_sign_language/sign_language.model.h5\n",
            "2719/2719 [==============================] - 180s 66ms/step - loss: 0.0973 - accuracy: 0.9675\n",
            "Epoch 6/10\n",
            "2719/2719 [==============================] - ETA: 0s - loss: 0.0822 - accuracy: 0.9724\n",
            "Epoch 6: accuracy improved from 0.96753 to 0.97238, saving model to /content/drive/MyDrive/predicting_sign_language/sign_language.model.h5\n",
            "2719/2719 [==============================] - 182s 67ms/step - loss: 0.0822 - accuracy: 0.9724\n",
            "Epoch 7/10\n",
            "2719/2719 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9746\n",
            "Epoch 7: accuracy improved from 0.97238 to 0.97463, saving model to /content/drive/MyDrive/predicting_sign_language/sign_language.model.h5\n",
            "2719/2719 [==============================] - 181s 67ms/step - loss: 0.0772 - accuracy: 0.9746\n",
            "Epoch 8/10\n",
            "2719/2719 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.9774\n",
            "Epoch 8: accuracy improved from 0.97463 to 0.97738, saving model to /content/drive/MyDrive/predicting_sign_language/sign_language.model.h5\n",
            "2719/2719 [==============================] - 181s 66ms/step - loss: 0.0698 - accuracy: 0.9774\n",
            "Epoch 9/10\n",
            "2719/2719 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.9788\n",
            "Epoch 9: accuracy improved from 0.97738 to 0.97880, saving model to /content/drive/MyDrive/predicting_sign_language/sign_language.model.h5\n",
            "2719/2719 [==============================] - 182s 67ms/step - loss: 0.0663 - accuracy: 0.9788\n",
            "Epoch 10/10\n",
            "2719/2719 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.9802\n",
            "Epoch 10: accuracy improved from 0.97880 to 0.98016, saving model to /content/drive/MyDrive/predicting_sign_language/sign_language.model.h5\n",
            "2719/2719 [==============================] - 176s 65ms/step - loss: 0.0619 - accuracy: 0.9802\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d3f297675e0>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "asl_image_model.fit(train_generator, epochs=10, callbacks=[checkpoint,Early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-d4PsHrzrXu"
      },
      "outputs": [],
      "source": [
        "# Path to test directory\n",
        "test_dir = 'asl_alphabet_test\\asl_alphabet_test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-difYIwzu8S"
      },
      "outputs": [],
      "source": [
        "# Function to load and preprocess an image\n",
        "def load_and_preprocess_image(img_path):\n",
        "    img = Image.open(img_path)\n",
        "    img = img.resize((64, 64))\n",
        "    img = np.array(img) / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VR7pDC35zxaA"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary to map class indices to class names\n",
        "class_indices = train_generator.class_indices\n",
        "class_labels = {v: k for k, v in class_indices.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uADIuMezz3Q",
        "outputId": "f04fdc4d-4d90-472c-84a6-44bf2573e62c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        }
      ],
      "source": [
        "# Predict on test images\n",
        "test_images = [f for f in os.listdir(test_dir) if f.endswith(('jpg', 'jpeg', 'png'))]\n",
        "predictions = []\n",
        "\n",
        "for img_name in test_images:\n",
        "    img_path = os.path.join(test_dir, img_name)\n",
        "    img = load_and_preprocess_image(img_path)\n",
        "    prediction = asl_image_model.predict(img)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "    predicted_class_label = class_labels[predicted_class_index]\n",
        "    predictions.append((img_name, predicted_class_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJFA-ibaz17j",
        "outputId": "a32ca3ff-1913-4819-ded9-5ca250e69b94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image: V_test.jpg, Predicted Class: V\n",
            "Image: nothing_test.jpg, Predicted Class: nothing\n",
            "Image: L_test.jpg, Predicted Class: L\n",
            "Image: O_test.jpg, Predicted Class: O\n",
            "Image: X_test.jpg, Predicted Class: X\n",
            "Image: F_test.jpg, Predicted Class: F\n",
            "Image: H_test.jpg, Predicted Class: H\n",
            "Image: J_test.jpg, Predicted Class: J\n",
            "Image: Y_test.jpg, Predicted Class: Y\n",
            "Image: R_test.jpg, Predicted Class: R\n",
            "Image: G_test.jpg, Predicted Class: G\n",
            "Image: A_test.jpg, Predicted Class: A\n",
            "Image: W_test.jpg, Predicted Class: W\n",
            "Image: I_test.jpg, Predicted Class: I\n",
            "Image: B_test.jpg, Predicted Class: B\n",
            "Image: space_test.jpg, Predicted Class: space\n",
            "Image: N_test.jpg, Predicted Class: N\n",
            "Image: E_test.jpg, Predicted Class: E\n",
            "Image: M_test.jpg, Predicted Class: M\n",
            "Image: Z_test.jpg, Predicted Class: Z\n",
            "Image: P_test.jpg, Predicted Class: P\n",
            "Image: U_test.jpg, Predicted Class: U\n",
            "Image: C_test.jpg, Predicted Class: C\n",
            "Image: D_test.jpg, Predicted Class: D\n",
            "Image: Q_test.jpg, Predicted Class: Q\n",
            "Image: T_test.jpg, Predicted Class: T\n",
            "Image: S_test.jpg, Predicted Class: S\n",
            "Image: K_test.jpg, Predicted Class: K\n"
          ]
        }
      ],
      "source": [
        "# Display predictions\n",
        "for img_name, predicted_class_label in predictions:\n",
        "    print(f\"Image: {img_name}, Predicted Class: {predicted_class_label}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
