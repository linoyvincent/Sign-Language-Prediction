{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9HpAqBAsKOT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from PIL import Image\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlBCiq8MsMnt"
      },
      "outputs": [],
      "source": [
        "# Define model architecture\n",
        "def create_asl_image_model(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FlNasBbsPS0"
      },
      "outputs": [],
      "source": [
        "# Path to train directory\n",
        "train_dir = 'asl_alphabet_train\\asl_alphabet_train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWFOrqfxsSEv",
        "outputId": "55e49af6-a991-40bd-bfe3-57ac0fa3d533"
      },
      "outputs": [],
      "source": [
        "# Data generators for training data\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, zoom_range=0.2, horizontal_flip=True)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, target_size=(64, 64), batch_size=32, class_mode='sparse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhgPsUWasU0Z"
      },
      "outputs": [],
      "source": [
        "# Create and train the model\n",
        "input_shape = (64, 64, 3)\n",
        "num_classes = len(os.listdir(train_dir)) \n",
        "asl_image_model = create_asl_image_model(input_shape, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IyyBzVV0rIF"
      },
      "outputs": [],
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    'sign_language.model.h5',\n",
        "    monitor='accuracy',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode='auto',\n",
        "    save_freq='epoch'\n",
        ")\n",
        "\n",
        "Early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='accuracy',\n",
        "    patience=8,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3TG45ArsYnj",
        "outputId": "acb6f9e8-7efd-4305-fded-e0ae1344d5bb"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "asl_image_model.fit(train_generator, epochs=10, callbacks=[checkpoint,Early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-d4PsHrzrXu"
      },
      "outputs": [],
      "source": [
        "# Path to test directory\n",
        "test_dir = 'asl_alphabet_test\\asl_alphabet_test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-difYIwzu8S"
      },
      "outputs": [],
      "source": [
        "# Function to load and preprocess an image\n",
        "def load_and_preprocess_image(img_path):\n",
        "    img = Image.open(img_path)\n",
        "    img = img.resize((64, 64))\n",
        "    img = np.array(img) / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VR7pDC35zxaA"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary to map class indices to class names\n",
        "class_indices = train_generator.class_indices\n",
        "class_labels = {v: k for k, v in class_indices.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uADIuMezz3Q",
        "outputId": "f04fdc4d-4d90-472c-84a6-44bf2573e62c"
      },
      "outputs": [],
      "source": [
        "# Predict on test images\n",
        "test_images = [f for f in os.listdir(test_dir) if f.endswith(('jpg', 'jpeg', 'png'))]\n",
        "predictions = []\n",
        "\n",
        "for img_name in test_images:\n",
        "    img_path = os.path.join(test_dir, img_name)\n",
        "    img = load_and_preprocess_image(img_path)\n",
        "    prediction = asl_image_model.predict(img)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "    predicted_class_label = class_labels[predicted_class_index]\n",
        "    predictions.append((img_name, predicted_class_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJFA-ibaz17j",
        "outputId": "a32ca3ff-1913-4819-ded9-5ca250e69b94"
      },
      "outputs": [],
      "source": [
        "# Display predictions\n",
        "for img_name, predicted_class_label in predictions:\n",
        "    print(f\"Image: {img_name}, Predicted Class: {predicted_class_label}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
